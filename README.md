# LLAMA Chat Interface

Interactive web interface for chatting with LLAMA AI models using WebLLM.

## GitHub Pages

This website is deployed using GitHub Pages. The site is automatically deployed when changes are pushed to the `main` branch.

### Local Development

To view the website locally, simply open `index.html` in your web browser. Note: Requires a WebGPU-compatible browser for model execution.

### Website Structure

- `index.html` - Main website page with chat interface
- `styles.css` - Styling and responsive design
- `.github/workflows/pages.yml` - GitHub Pages deployment workflow

## Features

- Interactive chat with LLAMA models in the browser
- No data sent to external servers - fully client-side
- Responsive design for mobile, tablet, and desktop
- Real-time model loading progress
- Streaming responses for better user experience
