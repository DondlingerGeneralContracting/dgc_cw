<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LLAMA Chat Interface - DGC CW</title>
    <link rel="stylesheet" href="styles.css">
</head>

<body>
    <nav class="navbar">
        <div class="container">
            <div class="logo">
                <h1>LLAMA Hub</h1>
            </div>
            <ul class="nav-menu">
                <li><a href="#home">Home</a></li>
                <li><a href="#chat">Chat</a></li>
                <li><a href="index2.html">üéÆ</a></li>
                <li><a href="#" id="settings-link">‚öôÔ∏è</a></li>
                <li><a href="#about">About</a></li>
                <li><a href="#contact">Contact</a></li>
            </ul>
        </div>
    </nav>

    <section id="home" class="hero">
        <div class="container">
            <div class="hero-content">
                <h2>Chat with LLAMA AI</h2>
                <p>Experience conversational AI powered by LLAMA in your browser.</p>
                <a href="#chat" class="cta-button">Start Chat</a>
            </div>
        </div>
    </section>

    <section id="chat" class="chat">
        <div class="container">
            <h2>LLAMA Chat</h2>
            <div class="chat-container">
                <div id="chat-history" class="chat-history"></div>
                <div class="chat-input">
                    <input type="text" id="user-input" placeholder="Type your message...">
                    <button id="voice-btn" title="Voice Input">üé§</button>
                    <button id="send-btn">Send</button>
                    <button id="speak-btn" title="Toggle Text-to-Speech">üîä</button>
                </div>
            </div>
        </div>
    </section>

    <!-- Settings Modal -->
    <div id="settings-modal" class="modal" style="display: none;">
        <div class="modal-content">
            <span class="close">&times;</span>
            <h2>Settings</h2>
            <label for="model-select">LLAMA Model:</label>
            <select id="model-select">
                <option value="Llama-3.3-70B-Instruct">Llama-3.3-70B-Instruct</option>
                <option value="Llama-3.3-8B-Instruct">Llama-3.3-8B-Instruct</option>
                <option value="Llama-4-Maverick-17B-128E-Instruct-FP8">Llama-4-Maverick-17B-128E-Instruct-FP8</option>
                <option value="Llama-4-Scout-17B-16E-Instruct-FP8">Llama-4-Scout-17B-16E-Instruct-FP8</option>
            </select>
            <p><small>Note: API key is configured server-side in Netlify.</small></p>
        </div>
    </div>

    <section id="about" class="about">
        <div class="container">
            <h2>About LLAMA</h2>
            <p>LLAMA is an open-source large language model developed by Meta. This interface allows you to interact
                with LLAMA models through our API, providing a seamless chat experience powered by the LLAMA API client.
            </p>
        </div>
    </section>

    <section id="contact" class="contact">
        <div class="container">
            <h2>Contact</h2>
            <p>Have questions about LLAMA or this interface? Reach out.</p>
            <div class="contact-info">
                <p>Email: dondlingergeneralcontracting@gmail.com</p>
                <p>Phone: (715) 321-2825</p>
                <p>Address: Your Address Here</p>
            </div>
        </div>
    </section>

    <footer>
        <div class="container">
            <p>&copy; 2024 LLAMA Hub. All rights reserved.</p>
        </div>
    </footer>
    <script>
        const chatHistory = document.getElementById('chat-history');
        const userInput = document.getElementById('user-input');
        const sendBtn = document.getElementById('send-btn');

        function addMessage(text, type) {
            const messageDiv = document.createElement('div');
            messageDiv.className = `message ${type}`;
            messageDiv.textContent = text;
            chatHistory.appendChild(messageDiv);
            chatHistory.scrollTop = chatHistory.scrollHeight;
        }

        async function sendMessage() {
            const message = userInput.value.trim();
            if (!message) return;

            addMessage(message, 'user');
            userInput.value = '';

            try {
                const payload = {
                    model: localStorage.getItem('llamaModel') || "Llama-3.3-70B-Instruct",
                messages: [
                    { role: "system", content: "You are a helpful assistant. Provide clear, accurate, and concise responses." },
                    { role: "user", content: message }
                ]
            const response = await fetch('https://llama-universal-netlify-project.netlify.app/.netlify/functions/llama-proxy?path=/chat/completions', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify(payload)
            });

            if (!response.ok) {
                throw new Error(`HTTP error! status: ${response.status}`);
            }

            const data = await response.json();
            addMessage(data.choices[0].message.content, 'llama');
            if (ttsEnabled) {
                speakText(data.choices[0].message.content);
            }
        } catch (error) {
            addMessage('Error generating response. Please check your API key and try again.', 'system');
            console.error('Error:', error);
        }
        }

        sendBtn.addEventListener('click', sendMessage);
        userInput.addEventListener('keypress', (e) => {
            if (e.key === 'Enter') sendMessage();
        });

        // Persistence
        function saveHistory() {
            const messages = Array.from(chatHistory.children).map(div => ({
                text: div.textContent,
                type: div.className.split(' ')[1]
            }));
            localStorage.setItem('chatHistory', JSON.stringify(messages));
        }

        function loadHistory() {
            const history = JSON.parse(localStorage.getItem('chatHistory') || '[]');
            history.forEach(msg => addMessage(msg.text, msg.type));
        }

        // Voice functionality
        let recognition;
        let isListening = false;
        let ttsEnabled = localStorage.getItem('ttsEnabled') === 'true';
        const voiceBtn = document.getElementById('voice-btn');
        const speakBtn = document.getElementById('speak-btn');

        speakBtn.textContent = ttsEnabled ? 'üîä' : 'üîá';
        speakBtn.onclick = () => {
            ttsEnabled = !ttsEnabled;
            localStorage.setItem('ttsEnabled', ttsEnabled);
            speakBtn.textContent = ttsEnabled ? 'üîä' : 'üîá';
        };

        voiceBtn.onclick = () => {
            if (isListening) {
                recognition.stop();
                isListening = false;
                voiceBtn.textContent = 'üé§';
            } else {
                startVoiceInput();
            }
        };

        function startVoiceInput() {
            if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
                alert('Speech recognition not supported in this browser.');
                return;
            }
            recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
            recognition.lang = 'en-US';
            recognition.interimResults = false;
            recognition.maxAlternatives = 1;
            recognition.onstart = () => {
                isListening = true;
                voiceBtn.textContent = 'üéôÔ∏è';
            };
            recognition.onresult = (event) => {
                const transcript = event.results[0][0].transcript;
                userInput.value = transcript;
                sendMessage();
            };
            recognition.onerror = (event) => {
                console.error('Speech recognition error:', event.error);
                isListening = false;
                voiceBtn.textContent = 'üé§';
            };
            recognition.onend = () => {
                isListening = false;
                voiceBtn.textContent = 'üé§';
            };
            recognition.start();
        }

        function speakText(text) {
            const utterance = new SpeechSynthesisUtterance(text);
            window.speechSynthesis.speak(utterance);
        }

        // Modify addMessage to save
        const originalAddMessage = addMessage;
        addMessage = function(text, type) {
            originalAddMessage(text, type);
            saveHistory();
        };

        // Settings Modal
        const settingsLink = document.getElementById('settings-link');
        const modal = document.getElementById('settings-modal');
        const closeBtn = document.getElementsByClassName('close')[0];
        const modelSelect = document.getElementById('model-select');

        settingsLink.onclick = function () {
            modal.style.display = 'block';
        }

        closeBtn.onclick = function () {
            modal.style.display = 'none';
        }

        window.onclick = function (event) {
            if (event.target == modal) {
                modal.style.display = 'none';
            }
        }

        // Load saved model
        const savedModel = localStorage.getItem('llamaModel') || 'Llama-3.3-70B-Instruct';
        modelSelect.value = savedModel;

        // Save model on change
        modelSelect.onchange = function () {
            localStorage.setItem('llamaModel', modelSelect.value);
        }

        loadHistory();
        if (chatHistory.children.length === 0) {
            addMessage('Welcome! Start chatting with LLAMA AI.', 'system');
        }
    </script>
</body>

</html>